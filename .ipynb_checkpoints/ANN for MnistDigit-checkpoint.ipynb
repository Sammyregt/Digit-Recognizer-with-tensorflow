{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10 #We are going to be classifying 10 digits\n",
    "img_rows, img_cols = 28, 28 #No of Pixels on height = 28 and width = 28 \n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the number and size of the training/testing samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e. we have 60,000 training samples and 10,000 testing one, with each sample an image of $28 \\times 28$ pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "img_idx = np.random.randint(0, x_test.shape[0])\n",
    "plt.imshow(x_test[img_idx], cmap=matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[img_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our images match their ground-truth label, which is good news!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as our Artifcial Neural Network only accepts column vectors, we need to _flatten_ the images into 1D vectors, i.e. vectors of shape `(1, 784)` (since $28 \\times 28 = 784$):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let us have a look at our pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel values between 0 and 255\n"
     ]
    }
   ],
   "source": [
    "print(\"Pixel values between {} and {}\".format(x_train.min(), x_train.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are normal integer values for images with 8 bits per channel (`uint8`)... These values may be however too big for some of our operations. For instance, given a too big input value, our sigmoid may return `nan` (\"_not a number_\") because of the exponential function it uses, which may \"overflow\" with a large input value.\n",
    "\n",
    "It is thus customary to *normalize* the input data, i.e. to scale the values between 0 and 1 (or -1 and 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized pixel values between 0.0 and 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "print(\"Normalized pixel values between {} and {}\".format(x_train.min(), x_train.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "# OR You can Decide to Use\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(), #Convert Image(28,28) to input of size 28*28=784\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 1.7099 - accuracy: 0.5381 - val_loss: 1.1822 - val_accuracy: 0.7621\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.9497 - accuracy: 0.8004 - val_loss: 0.7539 - val_accuracy: 0.8375\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.6837 - accuracy: 0.8456 - val_loss: 0.5913 - val_accuracy: 0.8628\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.5673 - accuracy: 0.8639 - val_loss: 0.5086 - val_accuracy: 0.8758\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.5026 - accuracy: 0.8743 - val_loss: 0.4590 - val_accuracy: 0.8838\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.4611 - accuracy: 0.8810 - val_loss: 0.4254 - val_accuracy: 0.8899\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.4321 - accuracy: 0.8865 - val_loss: 0.4016 - val_accuracy: 0.8947\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4104 - accuracy: 0.8906 - val_loss: 0.3834 - val_accuracy: 0.8981\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3935 - accuracy: 0.8940 - val_loss: 0.3687 - val_accuracy: 0.9005\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3797 - accuracy: 0.8965 - val_loss: 0.3568 - val_accuracy: 0.9032\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3683 - accuracy: 0.8988 - val_loss: 0.3469 - val_accuracy: 0.9052\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3585 - accuracy: 0.9009 - val_loss: 0.3385 - val_accuracy: 0.9060\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3500 - accuracy: 0.9026 - val_loss: 0.3308 - val_accuracy: 0.9082\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3424 - accuracy: 0.9049 - val_loss: 0.3244 - val_accuracy: 0.9104\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3357 - accuracy: 0.9063 - val_loss: 0.3182 - val_accuracy: 0.9113\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3295 - accuracy: 0.9076 - val_loss: 0.3132 - val_accuracy: 0.9125\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3238 - accuracy: 0.9092 - val_loss: 0.3081 - val_accuracy: 0.9132\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3186 - accuracy: 0.9106 - val_loss: 0.3033 - val_accuracy: 0.9150\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3137 - accuracy: 0.9119 - val_loss: 0.2995 - val_accuracy: 0.9164\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3092 - accuracy: 0.9129 - val_loss: 0.2953 - val_accuracy: 0.9176\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3049 - accuracy: 0.9141 - val_loss: 0.2917 - val_accuracy: 0.9180\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3008 - accuracy: 0.9150 - val_loss: 0.2879 - val_accuracy: 0.9195\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2970 - accuracy: 0.9166 - val_loss: 0.2844 - val_accuracy: 0.9198\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2932 - accuracy: 0.9178 - val_loss: 0.2816 - val_accuracy: 0.9213\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2897 - accuracy: 0.9188 - val_loss: 0.2785 - val_accuracy: 0.9212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fecc060860>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=25, verbose=1, validation_data=(x_test, y_test),batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "over **90%** of accuracy! This is much better. Congratulations, we implemented and trained our first neural network classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Can You Beat The Score(^-^)?</p>\n",
    "<p>Play Around the parameters</p>\n",
    "<p>Brush up on Week2 Materials including loss,optimizers,backpropagation etc</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
